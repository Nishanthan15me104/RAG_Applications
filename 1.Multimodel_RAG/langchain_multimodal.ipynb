{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishanthan15me104/Mini-Projects/blob/main/langchain_multimodal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "812a4dbc-fe04-4b84-bdf9-390045e30806",
      "metadata": {
        "id": "812a4dbc-fe04-4b84-bdf9-390045e30806"
      },
      "source": [
        "# Multi-modal RAG with LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecXPgawqG7XH",
      "metadata": {
        "id": "ecXPgawqG7XH"
      },
      "source": [
        "## SetUp\n",
        "\n",
        "Install the dependencies you need to run the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "133b74f6",
      "metadata": {
        "id": "133b74f6"
      },
      "outputs": [],
      "source": [
        "# for linux\n",
        "# !apt-get install poppler-utils tesseract-ocr libmagic-dev\n",
        "\n",
        "# for mac\n",
        "# !brew install poppler tesseract libmagic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fecea24",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-magic-binNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Using cached python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl.metadata (710 bytes)\n",
            "Using cached python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl (409 kB)\n",
            "Installing collected packages: python-magic-bin\n",
            "Successfully installed python-magic-bin-0.4.14\n"
          ]
        }
      ],
      "source": [
        "# pip install python-magic-bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2nDWBTrhn-_M",
      "metadata": {
        "id": "2nDWBTrhn-_M",
        "outputId": "7f1e98ab-538a-4c49-85ef-8590f83c4770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  DEPRECATION: Building 'antlr4-python3-runtime' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'antlr4-python3-runtime'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.72.0rc1 requires protobuf<7.0dev,>=6.30.0, but you have protobuf 5.29.4 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# %pip install -Uq \"unstructured[all-docs]\" pillow lxml pillow\n",
        "# %pip install -Uq chromadb tiktoken\n",
        "# %pip install -Uq langchain langchain-community langchain-openai langchain-groq\n",
        "# %pip install -Uq python_dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "91106e31",
      "metadata": {
        "id": "91106e31",
        "outputId": "fb35d92c-c338-4b78-bacb-5da648093f6e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# keys for the services we will use\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "# os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"sk-...\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7a923e53",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Now you can access the key like this:\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# if groq_api_key:\n",
        "#     print(f\"DEBUG: GROQ_API_KEY loaded: {groq_api_key[:5]}...{groq_api_key[-5:]}\") # Prints first/last 5 chars\n",
        "# else:\n",
        "#     print(\"DEBUG: GROQ_API_KEY not found in environment!\")\n",
        "\n",
        "# Or you can set it directly if you prefer, but it's already loaded into os.environ\n",
        "# os.environ[\"GROQ_API_KEY\"] = groq_api_key # This line would be redundant if you loaded it\n",
        "                   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74b56bde-1ba0-4525-a11d-cab02c5659e4",
      "metadata": {
        "id": "74b56bde-1ba0-4525-a11d-cab02c5659e4"
      },
      "source": [
        "## Extract the data\n",
        "\n",
        "Extract the elements of the PDF that we will be able to use in the retrieval process. These elements can be: Text, Images, Tables, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e62ec070",
      "metadata": {
        "id": "e62ec070"
      },
      "source": [
        "### Partition PDF tables, text, and images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d184a21f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pdftoppm: C:\\Program Files\\poppler-24.08.0\\Library\\bin\\pdftoppm.EXE\n",
            "tesseract: C:\\Program Files\\Tesseract-OCR\\tesseract.EXE\n",
            "poppler: None\n"
          ]
        }
      ],
      "source": [
        "# import shutil\n",
        "\n",
        "# print(\"pdftoppm:\", shutil.which(\"pdftoppm\"))\n",
        "# print(\"tesseract:\", shutil.which(\"tesseract\"))\n",
        "# print(\"poppler:\", shutil.which(\"poppler\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da9aa45c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install python-poppler\n",
        "# !pip install \"unstructured[pdf]\" unstructured-inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0a046528-8d22-4f4e-a520-962026562939",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308,
          "referenced_widgets": [
            "5246faf4e8194647a4b41d9de5a168f6",
            "c8f31460d7d5420db2c7840e287fac5b",
            "2ee43f14fa654a66ad0cfb559826f266",
            "e7e6388db19d47ceb06afc75fbb8486c",
            "922be25533bd448e9ce92614f7bd2677",
            "f63ee7f4234c45d48829e011f24eafde",
            "f8bcfb1381aa46d89034ea50e30b43cf",
            "00b164fb36864e53a8a73710d7d855cc",
            "64a0c4aa0bba4b6f8e8f5775a4341147",
            "2bcca7acc6f047d6ad4efbf1e5333c58",
            "052ec73371404595b7dec973dda308d4",
            "b12ba9f2111c44eeb5ae65820cc7d5d7",
            "15b9261bb07f4bbb95d276b92feabade",
            "5ffb0b594f51466284af380fd4d47b40",
            "fc994e0c5ced45c78c0b9bb6f19c073f",
            "c58471c60519419e9cdb3c7ff174d702",
            "0e7ed203dde24ec9a8d0f9c95a8877fd",
            "e64cfd87330d4b238596da66db63d984",
            "c13aff2b064743be941b4672550e56c9",
            "ef5fba5f330748faa9bd583d637087a6",
            "daabde9b4b764797af6b96370e40c1d2",
            "7d37b6f0ba8b4c5eb875635b98778d26",
            "a9a67e81e91e46e19b23f58dea634525",
            "2045ffddb5c4407f9235d1bf472e9ba5",
            "2df0c4cc59044ec8a59aadf2d5d2a9c9",
            "3095817ccc8f4ec6bae9b0c201d8e40a",
            "93205e664daa4921959605eb99dfa9cc",
            "9eab400a02dc46269e2537db44a78625",
            "415ddcb74bc2467fa9399039b7d0cafb",
            "b2fc825e7e6949e0a18f491ff261ac2b",
            "df6e6c84cc1c4c7b8cf5f8555eb42166",
            "547eb1582628438c9f0ef01554dfcdb4",
            "40b532d4d85740a2a16251bb321f489a",
            "ef897646c62444929b91935d3917b14d",
            "3bd05fe4e6bd4ea2b7bfcfba705369c5",
            "27e36e7f92d7417bb221fa95406cfb2f",
            "21318da3ae0644c28ec63983a34bd2ee",
            "c428c0bd915d455986b3193e9636ea80",
            "01ef4b60c3144e17afffb86281466bab",
            "3494ef9884224fa9a0a65999d7fc2945",
            "7185b40a7fa74088ad7ff6efb524e6b5",
            "cc6672c78dac468d9264efd90902c87d",
            "7ad056a7d71847d498f270ecac5cbf62",
            "309bad22d08c47af8d51942da599328e"
          ]
        },
        "id": "0a046528-8d22-4f4e-a520-962026562939",
        "outputId": "85bfb6b1-557f-4d4d-be94-b0c7200150e2",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nis44\\anaconda3\\RAG\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
          ]
        }
      ],
      "source": [
        "from unstructured.partition.pdf import partition_pdf\n",
        "\n",
        "output_path = \"./content/\"\n",
        "file_path = output_path + 'attention.pdf'\n",
        "\n",
        "# Reference: https://docs.unstructured.io/open-source/core-functionality/chunking\n",
        "chunks = partition_pdf(\n",
        "    filename=file_path,\n",
        "    infer_table_structure=True,            # extract tables\n",
        "    strategy=\"hi_res\",                     # mandatory to infer tables\n",
        "\n",
        "    extract_image_block_types=[\"Image\", \"Table\"],   # Add 'Table' to list to extract image of tables\n",
        "    # image_output_dir_path=output_path,   # if None, images and tables will saved in base64\n",
        "\n",
        "    extract_image_block_to_payload=True,   # if true, will extract base64 for API usage\n",
        "\n",
        "    chunking_strategy=\"by_title\",          # or 'basic'\n",
        "    max_characters=10000,                  # defaults to 500\n",
        "    combine_text_under_n_chars=2000,       # defaults to 0\n",
        "    new_after_n_chars=6000,\n",
        "\n",
        "    # extract_images_in_pdf=True,          # deprecated\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "038f6733",
      "metadata": {
        "id": "038f6733",
        "outputId": "9645206b-5b1d-45b5-ae1d-1883d78247f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{\"<class 'unstructured.documents.elements.CompositeElement'>\"}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We get 2 types of elements from the partition_pdf function\n",
        "set([str(type(el)) for el in chunks])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1dd44d1",
      "metadata": {},
      "source": [
        "to check chunks with table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea0ef44",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'texts' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m         images_b64\u001b[38;5;241m.\u001b[39mappend(el\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mimage_base64)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m         \u001b[43mtexts\u001b[49m\u001b[38;5;241m.\u001b[39mappend(el)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_table:\n\u001b[0;32m     22\u001b[0m     chunks_with_tables\u001b[38;5;241m.\u001b[39mappend(i)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'texts' is not defined"
          ]
        }
      ],
      "source": [
        "# chunks_with_tables = []\n",
        "# chunks_with_images = []\n",
        "\n",
        "# for i, chunk in enumerate(chunks):\n",
        "#     if str(type(chunk)) == \"<class 'unstructured.documents.elements.CompositeElement'>\":\n",
        "#         sub_elements = chunk.metadata.orig_elements\n",
        "        \n",
        "#         has_table = False\n",
        "#         has_image = False\n",
        "        \n",
        "#         for el in sub_elements:\n",
        "#             if str(type(el)) == \"<class 'unstructured.documents.elements.Table'>\":\n",
        "#                 has_table = True\n",
        "#                 tables.append(el)\n",
        "#             elif str(type(el)) == \"<class 'unstructured.documents.elements.Image'>\":\n",
        "#                 has_image = True\n",
        "#                 images_b64.append(el.metadata.image_base64)\n",
        "#             else:\n",
        "#                 texts.append(el)\n",
        "        \n",
        "#         if has_table:\n",
        "#             chunks_with_tables.append(i)\n",
        "#         if has_image:\n",
        "#             chunks_with_images.append(i)\n",
        "#     else:\n",
        "#         # You can also track if non-composite chunks have tables/images if needed\n",
        "#         pass\n",
        "\n",
        "# print(f\"Chunks containing tables: {chunks_with_tables}\")\n",
        "# print(f\"Chunks containing images: {chunks_with_images}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cccca0db",
      "metadata": {
        "id": "cccca0db",
        "outputId": "46f33bf2-d1d8-4bef-a0bf-d903ae2179d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<unstructured.documents.elements.Title at 0x1ca18f3d840>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x1ca18f3da20>,\n",
              " <unstructured.documents.elements.Footer at 0x1ca18f3dc00>,\n",
              " <unstructured.documents.elements.Title at 0x1ca0660aa40>,\n",
              " <unstructured.documents.elements.Title at 0x1ca060400a0>,\n",
              " <unstructured.documents.elements.Image at 0x1ca18f3db40>,\n",
              " <unstructured.documents.elements.Image at 0x1ca18f1a140>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x1ca18f3dd20>,\n",
              " <unstructured.documents.elements.Text at 0x1ca06041570>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x1ca18f3e050>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x1ca18f3e230>,\n",
              " <unstructured.documents.elements.Formula at 0x1ca18f3e410>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x1ca18f3e5f0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x1ca18f3e7d0>,\n",
              " <unstructured.documents.elements.Title at 0x1ca18f3e9b0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x1ca18f3eb90>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x1ca18f3ed70>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x1ca18f3ef50>,\n",
              " <unstructured.documents.elements.Text at 0x1ca06042c50>,\n",
              " <unstructured.documents.elements.Formula at 0x1ca18f3f370>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x1ca18f3dfc0>,\n",
              " <unstructured.documents.elements.NarrativeText at 0x1ca18f3e650>]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Each CompositeElement containes a bunch of related elements.\n",
        "# This makes it easy to use these elements together in a RAG pipeline.\n",
        "\n",
        "chunks[3].metadata.orig_elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b8766f03",
      "metadata": {
        "id": "b8766f03",
        "outputId": "8bd43211-e0a6-4d35-833e-ee7cb374c9b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'type': 'Table',\n",
              " 'element_id': '41fa8245-70cc-439c-bb00-242e71c691c6',\n",
              " 'text': 'Layer Type Complexity per Layer Sequential Maximum Path Length Operations Self-Attention O(n2 · d) O(1) O(1) Recurrent O(n · d2) O(n) O(n) Convolutional O(k · n · d2) O(1) O(logk(n)) Self-Attention (restricted) O(r · n · d) O(1) O(n/r)',\n",
              " 'metadata': {'detection_class_prob': 0.9258710145950317,\n",
              "  'coordinates': {'points': ((np.float64(324.7924499511719),\n",
              "     np.float64(313.3711853027344)),\n",
              "    (np.float64(324.7924499511719), np.float64(518.0281982421875)),\n",
              "    (np.float64(1356.664306640625), np.float64(518.0281982421875)),\n",
              "    (np.float64(1356.664306640625), np.float64(313.3711853027344))),\n",
              "   'system': 'PixelSpace',\n",
              "   'layout_width': 1700,\n",
              "   'layout_height': 2200},\n",
              "  'last_modified': '2025-05-21T16:40:06',\n",
              "  'text_as_html': '<table><thead><tr><th>Layer Type</th><th>Complexity per Layer</th><th>Sequential Operations</th><th>Maximum Path Length</th></tr></thead><tbody><tr><td>Self-Attention</td><td>O(n? - d)</td><td>O(1)</td><td>O(1)</td></tr><tr><td>Recurrent</td><td>O(n-d?)</td><td>O(n)</td><td>O(n)</td></tr><tr><td>Convolutional</td><td>O(k-n-d?)</td><td>olny</td><td>O(logx(n))</td></tr><tr><td>Self-Attention (restricted)</td><td>O(r-n-d)</td><td>ol)</td><td>O(n/r)</td></tr></tbody></table>',\n",
              "  'filetype': 'PPM',\n",
              "  'languages': ['eng'],\n",
              "  'page_number': 6,\n",
              "  'image_base64': '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',\n",
              "  'image_mime_type': 'image/jpeg'}}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This is what an extracted image looks like.\n",
        "# It contains the base64 representation only because we set the param extract_image_block_to_payload=True\n",
        "\n",
        "elements = chunks[5].metadata.orig_elements\n",
        "chunk_images = [el for el in elements if \"<class 'unstructured.documents.elements.Table'>\" in str(type(el))]\n",
        "chunk_images[0].to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26caebda",
      "metadata": {
        "id": "26caebda"
      },
      "source": [
        "### Separate extracted elements into tables, text, and images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0f7ad844",
      "metadata": {},
      "outputs": [],
      "source": [
        "tables = []\n",
        "texts = []\n",
        "images_b64 = []\n",
        "\n",
        "for chunk in chunks:\n",
        "    if str(type(chunk)) == \"<class 'unstructured.documents.elements.CompositeElement'>\":\n",
        "        # Get all original elements inside the composite\n",
        "        sub_elements = chunk.metadata.orig_elements\n",
        "\n",
        "        for el in sub_elements:\n",
        "            if str(type(el)) == \"<class 'unstructured.documents.elements.Table'>\":\n",
        "                tables.append(el)\n",
        "            elif str(type(el)) == \"<class 'unstructured.documents.elements.Image'>\":\n",
        "                images_b64.append(el.metadata.image_base64)\n",
        "            else:\n",
        "                texts.append(el)  # NarrativeText, Title, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bb098f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Table 1 ---\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'table' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, images_b64 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tables):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Table \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtable\u001b[49m\u001b[38;5;241m.\u001b[39mtext)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'table' is not defined"
          ]
        }
      ],
      "source": [
        "# for i, images_b64 in enumerate(tables):\n",
        "#     print(f\"\\n--- Table {i+1} ---\")\n",
        "#     print(table.text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8326a750",
      "metadata": {
        "id": "8326a750"
      },
      "outputs": [],
      "source": [
        "# # separate tables from texts\n",
        "# tables = []\n",
        "# texts = []\n",
        "\n",
        "# for chunk in chunks:\n",
        "#     if \"Table\" in str(type(chunk)):\n",
        "#         tables.append(chunk)\n",
        "\n",
        "#     if \"CompositeElement\" in str(type((chunk))):\n",
        "#         texts.append(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "df548e46",
      "metadata": {
        "id": "df548e46"
      },
      "outputs": [],
      "source": [
        "# Get the images from the CompositeElement objects\n",
        "def get_images_base64(chunks):\n",
        "    images_b64 = []\n",
        "    for chunk in chunks:\n",
        "        if \"CompositeElement\" in str(type(chunk)):\n",
        "            chunk_els = chunk.metadata.orig_elements\n",
        "            for el in chunk_els:\n",
        "                if \"Image\" in str(type(el)):\n",
        "                    images_b64.append(el.metadata.image_base64)\n",
        "    return images_b64\n",
        "\n",
        "images = get_images_base64(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9582f462",
      "metadata": {
        "id": "9582f462"
      },
      "source": [
        "#### Check what the images look like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "83158c36",
      "metadata": {
        "id": "83158c36",
        "outputId": "50ba7432-e879-4a64-e9f4-b47fdbeb0fbf"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import base64\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def display_base64_image(base64_code):\n",
        "    # Decode the base64 string to binary\n",
        "    image_data = base64.b64decode(base64_code)\n",
        "    # Display the image\n",
        "    display(Image(data=image_data))\n",
        "\n",
        "display_base64_image(images[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aa7f52f-bf5c-4ba4-af72-b2ccba59a4cf",
      "metadata": {
        "id": "0aa7f52f-bf5c-4ba4-af72-b2ccba59a4cf"
      },
      "source": [
        "## Summarize the data\n",
        "\n",
        "Create a summary of each element extracted from the PDF. This summary will be vectorized and used in the retrieval process."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b55862c",
      "metadata": {
        "id": "8b55862c"
      },
      "source": [
        "### Text and Table summaries\n",
        "\n",
        "We don't need a multimodal model to generate the summaries of the tables and the text. I will use open source models available on Groq."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b3d2bc",
      "metadata": {
        "id": "08b3d2bc",
        "outputId": "5c39beb3-2a0c-44b8-c2b2-48a4e451282c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# %pip install -Uq langchain-groq\n",
        "# %pip install -Uq langchain_openai\n",
        "# pip install langchain-huggingface \n",
        "# pip install langchain-google-genai\n",
        "# pip install google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "523e6ed2-2132-4748-bdb7-db765f20648d",
      "metadata": {
        "id": "523e6ed2-2132-4748-bdb7-db765f20648d"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "22c22e3f-42fb-4a4a-a87a-89f10ba8ab99",
      "metadata": {
        "id": "22c22e3f-42fb-4a4a-a87a-89f10ba8ab99"
      },
      "outputs": [],
      "source": [
        "# Prompt\n",
        "prompt_text = \"\"\"\n",
        "You are an assistant tasked with summarizing tables and text.\n",
        "Give a concise summary of the table or text.\n",
        "\n",
        "Respond only with the summary, no additionnal comment.\n",
        "Do not start your message by saying \"Here is a summary\" or anything like that.\n",
        "Just give the summary as it is.\n",
        "\n",
        "Table or text chunk: {element}\n",
        "\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
        "\n",
        "# Summary chain\n",
        "model = ChatGroq(temperature=0.5, model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
        "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b808cc78",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from more_itertools import chunked\n",
        "\n",
        "# Summarize text chunks in batches of 10\n",
        "text_summaries = []\n",
        "\n",
        "for batch in chunked(texts, 10):  # Process 10 text chunks at a time\n",
        "    summaries = summarize_chain.batch(\n",
        "        [{\"element\": str(t)} for t in batch],\n",
        "        {\"max_concurrency\": 1}\n",
        "    )\n",
        "    text_summaries.extend(summaries)\n",
        "    time.sleep(2)  # Wait 10 seconds between batches\n",
        "\n",
        "# Prepare table HTMLs\n",
        "tables_html = [table.metadata.text_as_html for table in tables]\n",
        "\n",
        "# Summarize table chunks in batches of 10\n",
        "table_summaries = []\n",
        "\n",
        "for batch in chunked(tables_html, 10):  # Process 10 table HTMLs at a time\n",
        "    summaries = summarize_chain.batch(\n",
        "        [{\"element\": str(html)} for html in batch],\n",
        "        {\"max_concurrency\": 1}\n",
        "    )\n",
        "    table_summaries.extend(summaries)\n",
        "    time.sleep(2)  # Wait 10 seconds between batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f176b374-aef0-48f4-a104-fb26b1dd6922",
      "metadata": {
        "id": "f176b374-aef0-48f4-a104-fb26b1dd6922"
      },
      "outputs": [],
      "source": [
        "# # Summarize text\n",
        "# text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 3})\n",
        "\n",
        "# # Summarize tables\n",
        "# tables_html = [table.metadata.text_as_html for table in tables]\n",
        "# table_summaries = summarize_chain.batch(tables_html, {\"max_concurrency\": 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c44cba01",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebd11635",
      "metadata": {},
      "source": [
        "to check no. of chunks and tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2d7d8d37",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of text chunks: 167\n",
            "Number of table chunks: 3\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of text chunks: {len(texts)}\")\n",
        "tables_html = [table.metadata.text_as_html for table in tables]\n",
        "print(f\"Number of table chunks: {len(tables_html)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1d172ad2",
      "metadata": {
        "id": "1d172ad2",
        "outputId": "1ba65afb-c9cd-4503-c154-db7841dfc1d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The element is Attention Is All You Need.',\n",
              " 'Ashish Vaswani works at Google Brain, his email is avaswani@google.com.',\n",
              " 'Noam Shazeer is affiliated with Google Brain, and his email is noam@google.com.',\n",
              " 'Niki Parmar is listed as an element, denoted with an asterisk.',\n",
              " 'The element is associated with Google Research and the email address nikip@google.com.',\n",
              " 'Jakob Uszkoreit works at Google Research, his email is usz@google.com.',\n",
              " 'Llion Jones works at Google Research, his email is llion@google.com.',\n",
              " 'Aidan N. Gomez is affiliated with the University of Toronto and can be contacted at aidan@cs.toronto.edu.',\n",
              " 'Łukasz Kaiser works at Google Brain and his email is lukaszkaiser@google.com.',\n",
              " 'Illia Polosukhin∗ ‡ is an element with a single value. \\n\\n Value: Illia Polosukhin∗ ‡',\n",
              " 'The email address is illia.polosukhin@gmail.com.',\n",
              " 'No information to summarize.',\n",
              " 'The Transformer, a new network architecture based solely on attention mechanisms, outperforms existing models in machine translation tasks, achieving 28.4 BLEU on English-to-German and 41.0 BLEU on English-to-French, with significantly less training time and greater parallelizability.',\n",
              " 'The content is an introduction, denoted as element 1.',\n",
              " 'Recurrent neural networks, particularly long short-term memory and gated recurrent neural networks, are state-of-the-art approaches in sequence modeling and transduction problems, such as language modeling and machine translation, with ongoing efforts to improve recurrent language models and encoder-decoder architectures.',\n",
              " 'The authors acknowledge the contributions of several team members: Jakob proposed replacing RNNs with self-attention; Ashish, Illia, and Noam designed and implemented the Transformer models; Niki, Llion, Lukasz, and Aidan worked on model variants, code, and implementation.',\n",
              " 'Work was performed while at Google Brain.',\n",
              " 'Work performed while at Google Research.',\n",
              " 'The 31st Conference on Neural Information Processing Systems, NIPS2017, was held in Long Beach, CA, USA.',\n",
              " 'Recurrent models compute sequences by generating hidden states as a function of previous states and inputs. This sequential nature limits parallelization and becomes critical at longer sequence lengths due to memory constraints. Recent work improved efficiency and performance through factorization and conditional computation, but the sequential constraint remains.',\n",
              " 'Attention mechanisms are a key component of sequence modeling and transduction models, enabling the modeling of dependencies regardless of distance in input or output sequences, and are typically used in conjunction with recurrent networks.',\n",
              " 'The Transformer is a proposed model architecture that uses an attention mechanism to draw global dependencies, allowing for more parallelization and achieving a new state of the art in translation quality with just 12 hours of training on 8 P100 GPUs.',\n",
              " 'The element is \"2 Background\".',\n",
              " 'The Extended Neural GPU, ByteNet, and ConvS2S use convolutional neural networks to compute hidden representations in parallel, but struggle with learning dependencies between distant positions due to increasing operations required. The Transformer reduces operations to a constant number, but faces reduced effective resolution, mitigated by Multi-Head Attention.',\n",
              " 'Self-attention is a mechanism that relates different positions of a single sequence to compute its representation, and has been successfully used in tasks such as reading comprehension, summarization, and sentence representation learning.',\n",
              " 'End-to-end memory networks use a recurrent attention mechanism and perform well on simple-language question answering and language modeling tasks.',\n",
              " 'The Transformer is the first transduction model to rely entirely on self-attention, not using sequence-aligned RNNs or convolution, and its advantages over other models will be discussed.',\n",
              " 'The element is about 3 Model Architecture.',\n",
              " 'Most competitive neural sequence transduction models have an encoder-decoder structure. The encoder maps an input sequence to a sequence of continuous representations. The decoder generates an output sequence one element at a time, auto-regressively consuming previously generated symbols as additional input.',\n",
              " 'The Transformer architecture uses stacked self-attention and point-wise, fully connected layers for both encoder and decoder.',\n",
              " 'The element is version 3.1, related to Encoder and Decoder Stacks.',\n",
              " 'The encoder consists of 6 identical layers, each with two sub-layers: a multi-head self-attention mechanism and a position-wise fully connected feed-forward network.',\n",
              " 'The element is 2.',\n",
              " 'The Transformer model architecture is shown in Figure 1.',\n",
              " 'The model uses a feed-forward network with two sub-layers, each with a residual connection and layer normalization, producing outputs of dimension 512.',\n",
              " \"The decoder consists of 6 identical layers, each with 3 sub-layers: 2 similar to the encoder and a third for multi-head attention over the encoder's output. The decoder uses residual connections and layer normalization, and masks self-attention to prevent attending to subsequent positions.\",\n",
              " 'The element is 3.2 Attention.',\n",
              " 'An attention function maps a query and key-value pairs to an output, all as vectors. The output is a weighted sum of values, with weights from a compatibility function between the query and corresponding keys.',\n",
              " 'The element is Scaled Dot-Product Attention, version 3.2.1.',\n",
              " 'The input for Scaled Dot-Product Attention consists of queries and keys of dimension dk, and values of dimension dv, which are computed using dot products.',\n",
              " 'The element is 3.',\n",
              " 'Scaled Dot-Product Attention is an element.',\n",
              " 'The element is Multi-Head Attention.',\n",
              " 'Figure 2 illustrates two attention mechanisms: Scaled Dot-Product Attention and Multi-Head Attention, which consists of multiple parallel attention layers.',\n",
              " 'The element is marked as √.',\n",
              " 'To compute weights, divide each key by a scaling factor dk, apply a softmax function to the result, and use it to weigh the values.',\n",
              " 'The attention function is computed on a set of queries, keys, and values packed into matrices Q, K, and V, to produce a matrix of outputs.',\n",
              " 'The Attention formula is: Attention(Q,K,V) = softmax(Q*K^T / sqrt(d_k))*V.',\n",
              " 'There are two common attention functions: additive attention, which uses a feed-forward network with one hidden layer, and dot-product attention, which is faster and more space-efficient, and can be implemented using optimized matrix multiplication code.',\n",
              " 'Additive attention outperforms dot product attention without scaling for larger values of dk. This is because large dot products push the softmax function into regions with extremely small gradients. Scaling dot products by 1/√dk counteracts this effect.',\n",
              " 'The element is 3.2.2 Multi-Head Attention.',\n",
              " 'The attention function is modified by linearly projecting queries, keys, and values into smaller dimensions (dk and dv) multiple times (h times), performing attention in parallel on each projection, and then concatenating and projecting the output to produce the final values.',\n",
              " 'Multi-head attention enables the model to attend to information from different representation subspaces at various positions, which is inhibited by averaging with a single attention head.',\n",
              " 'The dot product of two vectors with independent random variables of mean 0 and variance 1 has a mean of 0 and a variance of d, where d is the dimension of the vectors.',\n",
              " 'The element is 4.',\n",
              " 'The MultiHead attention mechanism is defined as the concatenation of h attention heads, where each head is computed using Attention(QW_Q_i, KW_K_i, V W_V_i) and then linearly transformed using W_O.',\n",
              " 'The projections use parameter matrices W Q, W O, W K, and W V with dimensions Rhdv×dmodel, Rdmodel×dk, and Rdmodel×dv respectively.',\n",
              " 'The model uses 8 parallel attention layers, or heads, with a reduced dimension of 64 for each head, resulting in a similar computational cost to single-head attention with full dimensionality.',\n",
              " 'Applications of Attention in the model are described in section 3.2.3.',\n",
              " 'The Transformer uses multi-head attention in three different ways.',\n",
              " 'In encoder-decoder attention layers, queries come from the previous decoder layer and memory keys and values come from the encoder output, allowing the decoder to attend over all input sequence positions.',\n",
              " \"The encoder's self-attention layers have keys, values, and queries that come from the same source, specifically the output of the previous layer, allowing each position to attend to all positions in the previous layer.\",\n",
              " 'Self-attention layers in the decoder allow attending to all positions up to and including the current position, while masking out illegal connections to prevent leftward information flow.',\n",
              " \"The element is about Position-wise Feed-Forward Networks, specifically denoted as '3.3'.\",\n",
              " 'Each layer in the encoder and decoder contains a fully connected feed-forward network with two linear transformations and a ReLU activation, applied separately and identically to each position.',\n",
              " 'The FFN (Feed Forward Network) formula is: FFN(x) = max(0, xW1 + b1)W2 + b2.',\n",
              " 'Linear transformations use same process across positions but with different layer parameters; input/output dimensionality is 512 and inner-layer dimensionality is 2048.',\n",
              " 'The element is about Embeddings and Softmax, specifically version 3.4.',\n",
              " 'The model uses learned embeddings to convert input and output tokens to vectors of dimension dmodel. The decoder output is converted to predicted next-token probabilities using a linear transformation and softmax function. The weight matrix is shared between embedding layers and the pre-softmax linear transformation, and weights are scaled by √ dmodel in the embedding layers.',\n",
              " 'Positional Encoding is denoted as 3.5.',\n",
              " 'The model needs to account for sequence order since it lacks recurrence and convolution, so positional encodings are added to input embeddings to provide token position information.',\n",
              " 'The element is 5.',\n",
              " 'Table1 describes properties of different layer types, including maximum path lengths, per-layer complexity, and minimum sequential operations, with factors depending on sequence length (n), representation dimension (d), kernel size (k), and neighborhood size (r).',\n",
              " 'Positional encodings have the same dimension as embeddings and can be summed; there are multiple choices for positional encodings, including learned and fixed ones.',\n",
              " 'The work uses sine and cosine functions with varying frequencies.',\n",
              " 'The table or text describes two equations for calculating PE(pos,2i) and PE(pos,2i+1) based on the position \"pos\", an imaginary unit \"i\", and a model \"dmodel\". The equations are: \\nPE(pos,2i) = sin(pos/10000 * 2i/dmodel) \\nPE(pos,2i+1) = cos(pos/10000 * 2i/dmodel)',\n",
              " 'The positional encoding is a sinusoid function where each dimension corresponds to a sinusoid with wavelengths in a geometric progression from 2π to 10000 · 2π, allowing the model to learn relative positions.',\n",
              " 'Using learned positional embeddings produced nearly identical results to sinusoidal embeddings, but sinusoidal was chosen as it may allow extrapolation to longer sequence lengths.',\n",
              " 'Self-Attention has 4 reasons or justifications, referred to as the 4 Whys of Self-Attention.',\n",
              " 'The text compares self-attention layers to recurrent and convolutional layers for mapping one sequence of symbol representations to another sequence of equal length, and outlines three key considerations for using self-attention.',\n",
              " 'There are two key considerations: the total computational complexity per layer and the amount of computation that can be parallelized, measured by the minimum number of sequential operations required.',\n",
              " 'The path length between long-range dependencies in a network affects the ability to learn such dependencies in sequence transduction tasks. Shorter paths between input and output positions make it easier to learn long-range dependencies. The maximum path length between any two input and output positions is compared across networks with different layer types.',\n",
              " 'Self-attention layers have a constant number of sequential operations, whereas recurrent layers require O(n) sequential operations. Self-attention layers are computationally faster when sequence length n is smaller than representation dimensionality d.',\n",
              " 'The element is 6.',\n",
              " 'The input sequence is centered around the output position to potentially increase the maximum path length to O(n/r), an approach to be investigated further.',\n",
              " \"A single convolutional layer with kernel width k < n doesn't connect all input and output positions. A stack of O(n/k) contiguous convolutional layers or O(logk(n)) dilated convolutional layers is required. Separable convolutions have a complexity of O(k · n · d + n · d2), comparable to self-attention and point-wise feed-forward layers when k = n.\",\n",
              " 'Self-attention in models can yield more interpretable results, with individual attention heads learning different tasks and exhibiting behavior related to sentence syntax and semantics.',\n",
              " 'The element is 5 Training.',\n",
              " 'The section describes the training regime for the models.',\n",
              " 'The element is related to training data and batching, version 5.1.',\n",
              " 'The study used two datasets: \\n- WMT2014 English-German with 4.5 million sentence pairs, 37,000 tokens, and byte-pair encoding.\\n- WMT2014 English-French with 36 million sentences, 32,000 word-piece vocabulary. \\nBatches contained approximately 25,000 source and 25,000 target tokens.',\n",
              " 'The element is 5.2, which relates to Hardware and Schedule.',\n",
              " 'The models were trained on a machine with 8 NVIDIA P100 GPUs. Base models took 0.4 seconds per step, were trained for 100,000 steps (12 hours). Big models took 1.0 second per step, were trained for 300,000 steps (3.5 days).',\n",
              " 'The element is related to optimization, specifically version 5.3 of an optimizer.',\n",
              " 'The Adam optimizer was used with β1 = 0.9, β2 = 0.98, and ε = 10^(-8), and a variable learning rate according to a specified formula.',\n",
              " 'The learning rate is calculated using the formula: lrate = d^(-0.5) * min(step_num - 0.5, step_num * warmup_steps^(-1.5)).',\n",
              " 'The learning rate increases linearly for the first 4000 training steps and then decreases proportionally to the inverse square root of the step number.',\n",
              " 'Regularization, version 5.4.',\n",
              " 'The company uses three types of regularization during training.',\n",
              " 'Dropout is applied to the output of each sub-layer and to the sums of embeddings and positional encodings in both encoder and decoder stacks, with a dropout rate of 0.1 for the base model.',\n",
              " 'The element is 7.',\n",
              " 'The Transformer model achieves better BLEU scores than previous state-of-the-art models on English-to-German and English-to-French tests, with significantly lower training costs.',\n",
              " 'Label smoothing with a value of 0.1 was used during training, which decreased perplexity but improved accuracy and BLEU score.',\n",
              " 'There are 6 results.',\n",
              " 'The element is 6.1 Machine Translation.',\n",
              " 'The big transformer model achieved a BLEU score of 28.4 on the WMT2014 English-to-German translation task, outperforming previous models by over 2.0 BLEU. Training took 3.5 days on 8 P100 GPUs. The base model also surpassed previous models at a lower training cost.',\n",
              " 'The big model achieved a BLEU score of 41.0 on the WMT2014 English-to-French translation task, outperforming previous single models at a lower training cost, using a dropout rate of 0.1.',\n",
              " 'The base models used the average of the last 5 checkpoints, while the big models used the average of the last 20 checkpoints. Beam search was used with a beam size of 4 and length penalty α = 0.6. The maximum output length was set to input length + 50.',\n",
              " 'The table compares translation quality and training costs of model architectures, estimating floating point operations used to train models by multiplying training time, number of GPUs, and GPU capacity.',\n",
              " \"Model variations are discussed in section 6.2, denoted as '6.2 Model Variations'.\",\n",
              " \"The authors evaluate the Transformer's components by modifying their base model and measuring performance changes on English-to-German translation using the newstest2013 development set and beam search. Results are presented in Table 3.\",\n",
              " 'Varying attention heads and dimensions while keeping computation constant shows single-head attention is 0.9 BLEU worse than the best setting, and quality drops with too many heads.',\n",
              " 'The TFLOPS values used are: K80 - 2.8, K40 - 3.7, M40 - 6.0, P100 - 9.5.',\n",
              " 'The element is 8.',\n",
              " 'The table compares variations of the Transformer architecture on English-to-German translation, using metrics from the newstest2013 development set, with perplexities calculated per-wordpiece.',\n",
              " 'The element is big.',\n",
              " 'The element is 6.',\n",
              " 'The element has a value of 1024.',\n",
              " 'The element has a value of 4096.',\n",
              " 'The element is 16.',\n",
              " 'The element value is 0.3.',\n",
              " 'The element has a designation of 300K4.33.',\n",
              " 'The element value is 26.4.',\n",
              " 'Reducing attention key size hurts model quality. Bigger models perform better, and dropout helps avoid overfitting. Replacing sinusoidal positional encoding with learned embeddings has a negligible effect on results.',\n",
              " 'The element is conclusion number 7.',\n",
              " 'The Transformer is a sequence transduction model based on attention, replacing recurrent layers with multi-headed self-attention in encoder-decoder architectures.',\n",
              " 'The Transformer achieves a new state of the art in WMT2014 English-to-German and English-to-French translation tasks, and trains significantly faster than architectures based on recurrent or convolutional layers.',\n",
              " 'The authors plan to apply attention-based models to tasks beyond text, exploring applications with diverse input/output modalities, and investigating efficient attention mechanisms for handling large inputs/outputs like images, audio, and video, as well as making generation less sequential.',\n",
              " 'The code used to train and evaluate models is available on GitHub at https://github.com/tensorflow/tensor2tensor.',\n",
              " 'The authors thank Nal Kalchbrenner and Stephan Gouws for their comments, corrections, and inspiration.',\n",
              " 'The element is 9.',\n",
              " 'The element is 213.',\n",
              " 'The element is References.',\n",
              " 'Authors Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton published a paper titled \"Layer normalization\" on arXiv in 2016, with the reference number arXiv:1607.06450.',\n",
              " 'Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio published a paper in 2014 titled \"Neural machine translation by jointly learning to align and translate\".',\n",
              " 'Denny Britz et al. explored neural machine translation architectures in 2017, publishing their findings in CoRR, abs/1703.03906.',\n",
              " 'Jianpeng Cheng, Li Dong, and Mirella Lapata published a paper on Long short-term memory-networks for machine reading on arXiv in 2016.',\n",
              " 'Authors: Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. \\nTitle: Learning phrase representations using RNN encoder-decoder for statistical machine translation.\\nPublication: CoRR, abs/1406.1078, 2014.',\n",
              " 'Francois Chollet published a paper in 2016 on Xception, a deep learning model using depthwise separable convolutions, available on arXiv as preprint arXiv:1610.02357.',\n",
              " 'Junyoung Chung et al. published a paper in 2014 on the empirical evaluation of gated recurrent neural networks on sequence modeling.',\n",
              " 'Jonas Gehring et al. published a paper on \"Convolutional sequence to sequence learning\" in 2017 on arXiv.',\n",
              " 'Alex Graves published a paper on generating sequences with recurrent neural networks in 2013 on arXiv.',\n",
              " 'Kaiming He et al. presented a paper on deep residual learning for image recognition at the 2016 IEEE Conference on Computer Vision and Pattern Recognition, pages 770-778.',\n",
              " 'The reference is a 2001 publication by Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber on the difficulty of learning long-term dependencies in recurrent neural networks.',\n",
              " 'Sepp Hochreiter and Jürgen Schmidhuber published a paper on Long Short-Term Memory in 1997 in the journal Neural Computation, volume 9, issue 8, pages 1735-1780.',\n",
              " 'Authors Jozefowicz, Vinyals, Schuster, Shazeer, and Wu published a 2016 arXiv preprint exploring language modeling limits, titled \"Exploring the limits of language modeling\".',\n",
              " 'Łukasz Kaiser and Ilya Sutskever presented on Neural GPUs learning algorithms at the 2016 International Conference on Learning Representations (ICLR).',\n",
              " 'The authors present a paper on neural machine translation in linear time, published on arXiv in 2017. The authors are Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Koray Kavukcuoglu.',\n",
              " 'Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush presented \"Structured attention networks\" at the International Conference on Learning Representations in 2017.',\n",
              " 'Diederik Kingma and Jimmy Ba published a method for stochastic optimization called Adam in ICLR, 2015.',\n",
              " 'Oleksii Kuchaiev and Boris Ginsburg published a paper on factorization tricks for LSTM networks in 2017 on arXiv.',\n",
              " 'Authors: Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. \\nTitle: A structured self-attentive sentence embedding. \\nPublication: arXiv preprint arXiv:1703.03130. \\nYear: 2017.',\n",
              " 'Samy Bengio and Łukasz Kaiser published a paper titled \"Can active memory replace attention?\" in Advances in Neural Information Processing Systems (NIPS) in 2016.',\n",
              " 'The element is 10.',\n",
              " 'A research paper on effective approaches to attention-based neural machine translation by Minh-Thang Luong, Hieu Pham, and Christopher D Manning, published in 2015 on arXiv.',\n",
              " 'Ankur Parikh et al. proposed a decomposable attention model in 2016 for Empirical Methods in Natural Language Processing.',\n",
              " 'Romain Paulus, Caiming Xiong, and Richard Socher proposed a deep reinforced model for abstractive summarization in their 2017 arXiv preprint.',\n",
              " 'Oﬁr Press and Lior Wolf published a 2016 arXiv preprint on improving language models using output embedding, titled \"Using the output embedding to improve language models\".',\n",
              " 'Rico Sennrich, Barry Haddow, and Alexandra Birch published a paper in 2015 on neural machine translation of rare words with subword units, titled \"Neural machine translation of rare words with subword units\" and available on arXiv as preprint arXiv:1508.07909.',\n",
              " 'Researchers presented a method for creating large neural networks using a sparsely-gated mixture-of-experts layer, publishing their findings in an arXiv preprint in 2017.',\n",
              " 'The paper \"Dropout: a simple way to prevent neural networks from overfitting\" was published in 2014 in the Journal of Machine Learning Research, by Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.',\n",
              " 'Sainbayar Sukhbaatar et al. published a paper on \"End-to-end memory networks\" in Advances in Neural Information Processing Systems 28, pages 2440-2448, in 2015.',\n",
              " 'Ilya Sutskever, Oriol Vinyals, and Quoc VV Le introduced sequence to sequence learning with neural networks in Advances in Neural Information Processing Systems in 2014.',\n",
              " 'The authors of a 2015 research paper titled \"Rethinking the inception architecture for computer vision\" are Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.',\n",
              " 'Researchers from Google presented a neural machine translation system, detailing its architecture and performance in a 2016 arXiv preprint.',\n",
              " 'Authors: Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. \\nTitle: Deep recurrent models with fast-forward connections for neural machine translation. \\nPublication: CoRR, abs/1606.04199, 2016.',\n",
              " \"The element is '11'.\"]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1feadda-8171-4aed-9a60-320a88dc9ee1",
      "metadata": {
        "id": "b1feadda-8171-4aed-9a60-320a88dc9ee1"
      },
      "source": [
        "### Image summaries\n",
        "\n",
        "We will use gpt-4o-mini to produce the image summaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "939ed47f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_google_genai  import GoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "262e2f58",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import google.generativeai as genai\n",
        "\n",
        "# import os\n",
        "\n",
        "# # Make sure your GOOGLE_API_KEY is set as an environment variable\n",
        "# # os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY\" # Uncomment and replace if you prefer to set it directly in code (less secure)\n",
        "\n",
        "# if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "#     print(\"Error: GOOGLE_API_KEY environment variable not set.\")\n",
        "#     print(\"Please set your GOOGLE_API_KEY before running this script.\")\n",
        "# else:\n",
        "#     genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "#     print(\"Fetching available models...\")\n",
        "#     for m in genai.list_models():\n",
        "#         if \"generateContent\" in m.supported_generation_methods:\n",
        "#             print(f\"Model ID: {m.name}, Supported Methods: {m.supported_generation_methods}\")\n",
        "#             # You might also check m.vision for models that support image input\n",
        "#             # if m.vision:\n",
        "#             #     print(f\"  (Supports Vision)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9e6b1d97-4245-45ac-95ba-9bc1cfd10182",
      "metadata": {
        "id": "9e6b1d97-4245-45ac-95ba-9bc1cfd10182"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "prompt_template = \"\"\"Describe the image in detail. For context,\n",
        "                  the image is part of a research paper explaining the transformers\n",
        "                  architecture. Be specific about graphs, such as bar plots.\"\"\"\n",
        "messages = [\n",
        "    (\n",
        "        \"user\",\n",
        "        [\n",
        "            {\"type\": \"text\", \"text\": prompt_template},\n",
        "            {\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image}\"},\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "]\n",
        "llm = ChatGroq(model=\"meta-llama/llama-4-maverick-17b-128e-instruct\", temperature=0.1)\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "\n",
        "image_summaries = chain.batch(images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "laF_8o1gzHT0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laF_8o1gzHT0",
        "outputId": "f82547af-0885-4d78-9f50-940dd9e6551e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The image presents a detailed diagram of the Transformer architecture, a type of neural network designed for natural language processing tasks. The diagram is divided into two main sections: the encoder and the decoder.\\n\\n**Encoder:**\\n\\n*   The encoder takes in a sequence of input tokens, which are embedded into a higher-dimensional space using an **Input Embedding** layer.\\n*   The embedded inputs are then added to **Positional Encoding**, which provides information about the position of each token in the sequence.\\n*   The resulting vector is fed into a series of identical layers, each consisting of two sub-layers:\\n    *   **Multi-Head Attention**: This sub-layer applies self-attention to the input sequence, allowing the model to attend to different parts of the input sequence simultaneously.\\n    *   **Feed Forward**: This sub-layer applies a feed-forward neural network to the output of the multi-head attention sub-layer.\\n*   The output of each layer is passed through an **Add & Norm** layer, which applies layer normalization and residual connection.\\n\\n**Decoder:**\\n\\n*   The decoder takes in a sequence of output tokens, which are embedded into a higher-dimensional space using an **Output Embedding** layer.\\n*   The embedded outputs are then added to **Positional Encoding**, which provides information about the position of each token in the sequence.\\n*   The resulting vector is fed into a series of identical layers, each consisting of three sub-layers:\\n    *   **Masked Multi-Head Attention**: This sub-layer applies self-attention to the output sequence, with a mask to prevent the model from attending to future tokens.\\n    *   **Multi-Head Attention**: This sub-layer applies attention to the output of the encoder, allowing the model to attend to different parts of the input sequence.\\n    *   **Feed Forward**: This sub-layer applies a feed-forward neural network to the output of the multi-head attention sub-layer.\\n*   The output of each layer is passed through an **Add & Norm** layer, which applies layer normalization and residual connection.\\n\\n**Output Probabilities:**\\n\\n*   The final output of the decoder is passed through a **Linear** layer, followed by a **Softmax** layer, to produce a probability distribution over the possible output tokens.\\n\\nThe diagram illustrates the Transformer architecture, highlighting the key components and their interactions. The use of identical layers in both the encoder and decoder allows for parallelization and efficient computation. The diagram does not contain any graphs, such as bar plots.',\n",
              " 'The image presents a flowchart illustrating the process of self-attention in the Transformer architecture, a key component of many modern natural language processing models.\\n\\n**Flowchart Structure**\\n\\nThe flowchart consists of five rectangular boxes, each representing a distinct operation, connected by arrows that indicate the direction of data flow. The boxes are labeled as follows:\\n\\n*   MatMul (Matrix Multiplication)\\n*   SoftMax\\n*   Mask (optional)\\n*   Scale\\n*   MatMul (Matrix Multiplication)\\n\\n**Input and Output**\\n\\nThe flowchart takes three inputs:\\n\\n*   Q (Query)\\n*   K (Key)\\n*   V (Value)\\n\\nThese inputs are fed into the first MatMul operation, which computes the attention scores.\\n\\n**Operations**\\n\\nThe operations are performed in the following order:\\n\\n1.  **MatMul**: The first matrix multiplication operation computes the attention scores by multiplying Q and K.\\n2.  **Scale**: The attention scores are scaled to prevent extremely large values.\\n3.  **Mask (optional)**: An optional masking operation is applied to the scaled attention scores to prevent the model from attending to certain positions (e.g., padding tokens).\\n4.  **SoftMax**: The SoftMax function is applied to the masked attention scores to obtain a probability distribution over the attention weights.\\n5.  **MatMul**: The final matrix multiplication operation computes the weighted sum of V based on the attention weights.\\n\\n**Output**\\n\\nThe output of the flowchart is the result of the final MatMul operation, which represents the self-attention output.\\n\\n**Visual Representation**\\n\\nThe flowchart is depicted in a simple and clear manner, with each operation represented by a distinct color:\\n\\n*   MatMul: Purple\\n*   SoftMax: Green\\n*   Mask: Pink\\n*   Scale: Yellow\\n\\nThe use of different colors helps to visually distinguish between the various operations and makes the flowchart easy to follow.\\n\\n**Context**\\n\\nThe image is likely used in a research paper or educational material to explain the Transformer architecture and its self-attention mechanism. The flowchart provides a concise and intuitive representation of the self-attention process, making it easier for readers to understand the underlying mechanics of the Transformer model.',\n",
              " 'The image presents a flowchart illustrating the process of Scaled Dot-Product Attention, a key component in the Transformer architecture used in natural language processing and other applications. The flowchart is divided into several sections, each representing a different stage in the attention mechanism.\\n\\n*   **Input Vectors**\\n    *   The flowchart begins with three input vectors: V, K, and Q.\\n    *   These vectors are typically derived from the input data, such as text or images.\\n*   **Linear Transformations**\\n    *   Each input vector undergoes a linear transformation, represented by the \"Linear\" boxes.\\n    *   These transformations are learned during training and are used to project the input vectors into a higher-dimensional space.\\n*   **Scaled Dot-Product Attention**\\n    *   The transformed vectors are then fed into the Scaled Dot-Product Attention mechanism.\\n    *   This mechanism computes the attention weights by taking the dot product of the query (Q) and key (K) vectors, scaling the result, and applying a softmax function.\\n    *   The attention weights are then used to compute a weighted sum of the value (V) vectors.\\n*   **Concatenation and Linear Transformation**\\n    *   The output of the Scaled Dot-Product Attention mechanism is concatenated with other outputs (not shown in the image).\\n    *   The concatenated output is then passed through another linear transformation, represented by the \"Linear\" box at the top of the flowchart.\\n*   **Output**\\n    *   The final output of the flowchart is the result of the linear transformation applied to the concatenated output.\\n\\nIn summary, the image illustrates the Scaled Dot-Product Attention mechanism, a crucial component of the Transformer architecture. The flowchart shows how the input vectors are transformed, attention weights are computed, and the output is generated through a series of linear transformations and concatenations.']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "aHNDEd_2txQI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "aHNDEd_2txQI",
        "outputId": "fbd7c64e-f463-4203-e1ca-f79c7426aaf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image presents a detailed diagram of the Transformer architecture, a type of neural network designed for natural language processing tasks. The diagram is divided into two main sections: the encoder and the decoder.\n",
            "\n",
            "**Encoder:**\n",
            "\n",
            "*   The encoder takes in a sequence of input tokens, which are embedded into a higher-dimensional space using an **Input Embedding** layer.\n",
            "*   The embedded inputs are then added to **Positional Encoding**, which provides information about the position of each token in the sequence.\n",
            "*   The resulting vector is fed into a series of identical layers, each consisting of two sub-layers:\n",
            "    *   **Multi-Head Attention**: This sub-layer applies self-attention to the input sequence, allowing the model to attend to different parts of the input sequence simultaneously.\n",
            "    *   **Feed Forward**: This sub-layer applies a feed-forward neural network to the output of the multi-head attention sub-layer.\n",
            "*   The output of each layer is passed through an **Add & Norm** layer, which applies layer normalization and residual connection.\n",
            "\n",
            "**Decoder:**\n",
            "\n",
            "*   The decoder takes in a sequence of output tokens, which are embedded into a higher-dimensional space using an **Output Embedding** layer.\n",
            "*   The embedded outputs are then added to **Positional Encoding**, which provides information about the position of each token in the sequence.\n",
            "*   The resulting vector is fed into a series of identical layers, each consisting of three sub-layers:\n",
            "    *   **Masked Multi-Head Attention**: This sub-layer applies self-attention to the output sequence, with a mask to prevent the model from attending to future tokens.\n",
            "    *   **Multi-Head Attention**: This sub-layer applies attention to the output of the encoder, allowing the model to attend to different parts of the input sequence.\n",
            "    *   **Feed Forward**: This sub-layer applies a feed-forward neural network to the output of the multi-head attention sub-layer.\n",
            "*   The output of each layer is passed through an **Add & Norm** layer, which applies layer normalization and residual connection.\n",
            "\n",
            "**Output Probabilities:**\n",
            "\n",
            "*   The final output of the decoder is passed through a **Linear** layer, followed by a **Softmax** layer, to produce a probability distribution over the possible output tokens.\n",
            "\n",
            "The diagram illustrates the Transformer architecture, highlighting the key components and their interactions. The use of identical layers in both the encoder and decoder allows for parallelization and efficient computation. The diagram does not contain any graphs, such as bar plots.\n"
          ]
        }
      ],
      "source": [
        "print(image_summaries[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67b030d4-2ac5-41b6-9245-fc3ba5771d87",
      "metadata": {
        "id": "67b030d4-2ac5-41b6-9245-fc3ba5771d87"
      },
      "source": [
        "## Load data and summaries to vectorstore"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb4d2379",
      "metadata": {
        "id": "bb4d2379"
      },
      "source": [
        "### Create the vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9d8d7a34-69e0-49a2-b9f7-1a4e7b26d78f",
      "metadata": {
        "id": "9d8d7a34-69e0-49a2-b9f7-1a4e7b26d78f",
        "outputId": "c91d7a77-d820-446f-a751-15f5d4668e8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nis44\\AppData\\Local\\Temp\\ipykernel_35272\\2574808026.py:12: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=hf_embeddings)\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.schema.document import Document\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "\n",
        "\n",
        "hf_embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(collection_name=\"multi_modal_rag\", embedding_function=hf_embeddings)\n",
        "\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryStore()\n",
        "id_key = \"doc_id\"\n",
        "\n",
        "# The retriever (empty to start)\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    id_key=id_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf26669",
      "metadata": {
        "id": "2bf26669"
      },
      "source": [
        "### Load the summaries and link the to the original data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "1792e683",
      "metadata": {
        "id": "1792e683"
      },
      "outputs": [],
      "source": [
        "# Add texts\n",
        "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
        "summary_texts = [\n",
        "    Document(page_content=summary, metadata={id_key: doc_ids[i]}) for i, summary in enumerate(text_summaries)\n",
        "]\n",
        "retriever.vectorstore.add_documents(summary_texts)\n",
        "retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
        "\n",
        "# Add tables\n",
        "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
        "summary_tables = [\n",
        "    Document(page_content=summary, metadata={id_key: table_ids[i]}) for i, summary in enumerate(table_summaries)\n",
        "]\n",
        "retriever.vectorstore.add_documents(summary_tables)\n",
        "retriever.docstore.mset(list(zip(table_ids, tables)))\n",
        "\n",
        "# Add image summaries\n",
        "img_ids = [str(uuid.uuid4()) for _ in images]\n",
        "summary_img = [\n",
        "    Document(page_content=summary, metadata={id_key: img_ids[i]}) for i, summary in enumerate(image_summaries)\n",
        "]\n",
        "retriever.vectorstore.add_documents(summary_img)\n",
        "retriever.docstore.mset(list(zip(img_ids, images)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b45fb81-46b1-426e-aa2c-01aed4eac700",
      "metadata": {
        "id": "4b45fb81-46b1-426e-aa2c-01aed4eac700"
      },
      "source": [
        "### Check retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1bea75fe-85af-4955-a80c-6e0b44a8e215",
      "metadata": {
        "id": "1bea75fe-85af-4955-a80c-6e0b44a8e215"
      },
      "outputs": [],
      "source": [
        "# Retrieve\n",
        "docs = retriever.invoke(\n",
        "    \"who are the authors of the paper?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a0290c78",
      "metadata": {
        "id": "a0290c78",
        "outputId": "d19cdecf-c9e6-4b40-f996-06041a7f0ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful comments, corrections and inspiration.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural machine translation architectures. CoRR, abs/1703.03906, 2017.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Jakob Uszkoreit∗ Google Research usz@google.com\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for doc in docs:\n",
        "    print(str(doc) + \"\\n\\n\" + \"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69060724-e390-4dda-8250-5f86025c874a",
      "metadata": {
        "id": "69060724-e390-4dda-8250-5f86025c874a"
      },
      "source": [
        "## RAG pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "771a47fa-1267-4db8-a6ae-5fde48bbc069",
      "metadata": {
        "id": "771a47fa-1267-4db8-a6ae-5fde48bbc069"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from base64 import b64decode\n",
        "\n",
        "\n",
        "def parse_docs(docs):\n",
        "    \"\"\"Split base64-encoded images and texts\"\"\"\n",
        "    b64 = []\n",
        "    text = []\n",
        "    for doc in docs:\n",
        "        try:\n",
        "            b64decode(doc)\n",
        "            b64.append(doc)\n",
        "        except Exception as e:\n",
        "            text.append(doc)\n",
        "    return {\"images\": b64, \"texts\": text}\n",
        "\n",
        "\n",
        "def build_prompt(kwargs):\n",
        "\n",
        "    docs_by_type = kwargs[\"context\"]\n",
        "    user_question = kwargs[\"question\"]\n",
        "\n",
        "    context_text = \"\"\n",
        "    if len(docs_by_type[\"texts\"]) > 0:\n",
        "        for text_element in docs_by_type[\"texts\"]:\n",
        "            context_text += text_element.text\n",
        "\n",
        "    # construct prompt with context (including images)\n",
        "    prompt_template = f\"\"\"\n",
        "    Answer the question based only on the following context, which can include text, tables, and the below image.\n",
        "    Context: {context_text}\n",
        "    Question: {user_question}\n",
        "    \"\"\"\n",
        "\n",
        "    prompt_content = [{\"type\": \"text\", \"text\": prompt_template}]\n",
        "\n",
        "    if len(docs_by_type[\"images\"]) > 0:\n",
        "        for image in docs_by_type[\"images\"]:\n",
        "            prompt_content.append(\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
        "                }\n",
        "            )\n",
        "\n",
        "    return ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            HumanMessage(content=prompt_content),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "chain = (\n",
        "    {\n",
        "        \"context\": retriever | RunnableLambda(parse_docs),\n",
        "        \"question\": RunnablePassthrough(),\n",
        "    }\n",
        "    | RunnableLambda(build_prompt)\n",
        "    | ChatGroq(model=\"meta-llama/llama-4-maverick-17b-128e-instruct\", temperature=0.1)\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain_with_sources = {\n",
        "    \"context\": retriever | RunnableLambda(parse_docs),\n",
        "    \"question\": RunnablePassthrough(),\n",
        "} | RunnablePassthrough().assign(\n",
        "    response=(\n",
        "        RunnableLambda(build_prompt)\n",
        "        | ChatGroq(model=\"meta-llama/llama-4-maverick-17b-128e-instruct\", temperature=0.1)\n",
        "        | StrOutputParser()\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea8414a8-65ee-4e11-8154-029b454f46af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "ea8414a8-65ee-4e11-8154-029b454f46af",
        "outputId": "2edf5f7e-9165-46ef-e710-cc945b78b230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The attention mechanism is a function that maps a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, with the weights determined by a compatibility function that measures how well the query aligns with each key.\n",
            "\n",
            "In mathematical terms, the attention function can be expressed as:\n",
            "\n",
            "\\[ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\]\n",
            "\n",
            "Here, \\(Q\\) represents the queries, \\(K\\) the keys, and \\(V\\) the values. The dot products of the queries and keys are scaled by the square root of the dimension of the keys (\\(d_k\\)) to prevent large values that could push the softmax function into regions with small gradients. This attention mechanism allows the model to focus on different parts of the input sequence when producing an output, enhancing its ability to handle dependencies and context within the data. \n",
            "\n",
            "Additionally, multi-head attention extends this concept by performing multiple attention operations in parallel, allowing the model to attend to information from different representation subspaces simultaneously.\n"
          ]
        }
      ],
      "source": [
        "response = chain.invoke(\n",
        "    \"What is the attention mechanism?\"\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e4adfeba",
      "metadata": {
        "id": "e4adfeba",
        "outputId": "7c82360d-4c90-4cd1-9db4-7ba815277bbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response: MultiHead(Q,K,V ) = Concat(head1,...,headh)W O where headi = Attention(QW Q i ,KW K i ,V W V i ). Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions.\n",
            "\n",
            "\n",
            "Context:\n",
            "MultiHead(Q,K,V ) = Concat(head1,...,headh)W O where headi = Attention(QW Q i ,KW K i ,V W V i )\n",
            "Page number:  5\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.\n",
            "Page number:  4\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "The Transformer uses multi-head attention in three different ways:\n",
            "Page number:  5\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Multi-Head Attention\n",
            "Page number:  4\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = chain_with_sources.invoke(\n",
        "    \"What is multihead?\"\n",
        ")\n",
        "\n",
        "print(\"Response:\", response['response'])\n",
        "\n",
        "print(\"\\n\\nContext:\")\n",
        "for text in response['context']['texts']:\n",
        "    print(text.text)\n",
        "    print(\"Page number: \", text.metadata.page_number)\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "for image in response['context']['images']:\n",
        "    display_base64_image(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90cd3714",
      "metadata": {
        "id": "90cd3714"
      },
      "source": [
        "## References\n",
        "\n",
        "- [LangChain Inspiration](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb?ref=blog.langchain.dev)\n",
        "- [Multivector Storage](https://python.langchain.com/docs/how_to/multi_vector/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "74b56bde-1ba0-4525-a11d-cab02c5659e4",
        "8b55862c",
        "b1feadda-8171-4aed-9a60-320a88dc9ee1",
        "bb4d2379",
        "2bf26669",
        "4b45fb81-46b1-426e-aa2c-01aed4eac700",
        "69060724-e390-4dda-8250-5f86025c874a"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "RAG",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
