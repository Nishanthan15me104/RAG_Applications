{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19011a0f-f7c0-4cd1-80e2-9dac0ccaaf66",
   "metadata": {},
   "source": [
    "### Setup RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcbdfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragas\n",
      "  Downloading ragas-0.2.15-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from ragas) (2.2.6)\n",
      "Requirement already satisfied: datasets in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from ragas) (3.6.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from ragas) (0.9.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from ragas) (0.3.25)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from ragas) (0.3.60)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from ragas) (0.3.24)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from ragas) (0.3.17)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from ragas) (1.6.0)\n",
      "Collecting appdirs (from ragas)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pydantic>=2 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from ragas) (2.11.4)\n",
      "Requirement already satisfied: openai>1 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from ragas) (1.79.0)\n",
      "Collecting diskcache>=5.6.3 (from ragas)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from openai>1->ragas) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from openai>1->ragas) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from openai>1->ragas) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from openai>1->ragas) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from openai>1->ragas) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from openai>1->ragas) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from openai>1->ragas) (4.13.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from anyio<5,>=3.5.0->openai>1->ragas) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from pydantic>=2->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from pydantic>=2->ragas) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from pydantic>=2->ragas) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from tqdm>4->openai>1->ragas) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from datasets->ragas) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from datasets->ragas) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from datasets->ragas) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from datasets->ragas) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from datasets->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from datasets->ragas) (0.31.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from datasets->ragas) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from datasets->ragas) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (3.11.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from requests>=2.32.2->datasets->ragas) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from requests>=2.32.2->datasets->ragas) (2.4.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from langchain->ragas) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from langchain->ragas) (0.3.42)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from langchain->ragas) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from langchain-core->ragas) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (0.23.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from langchain-community->ragas) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from langchain-community->ragas) (0.4.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas) (1.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from tiktoken->ragas) (2024.11.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nis44\\anaconda3\\rag\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\n",
      "Downloading ragas-0.2.15-py3-none-any.whl (190 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: appdirs, diskcache, ragas\n",
      "\n",
      "   -------------------------- ------------- 2/3 [ragas]\n",
      "   -------------------------- ------------- 2/3 [ragas]\n",
      "   -------------------------- ------------- 2/3 [ragas]\n",
      "   ---------------------------------------- 3/3 [ragas]\n",
      "\n",
      "Successfully installed appdirs-1.4.4 diskcache-5.6.3 ragas-0.2.15\n"
     ]
    }
   ],
   "source": [
    "# pip install faiss-cpu\n",
    "# !pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b454567-7ea1-4ab4-82ce-e0365f8fdf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import faiss\n",
    "import openai\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"groq_api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02ce22c9-b8c0-49ea-a9bb-89a5ca4ffca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"Paris is the capital and most populous city of France. The city is famed for the Eiffel Tower.\",\n",
    "    \"Jane Austen was an English novelist best known for 'Pride and Prejudice' and 'Sense and Sensibility'.\",\n",
    "    \"The Great Wall of China is a series of fortifications built to protect the ancient Chinese states.\",\n",
    "    \"Mount Everest, part of the Himalayas, is Earth’s highest mountain above sea level.\",\n",
    "    \"Mike loves the color pink more than any other color.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e38813-6dbe-413d-84ed-72c70fb21059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = openai.OpenAI()\n",
    "# def get_embedding(text):\n",
    "#     response = client.embeddings.create(model=\"text-embedding-3-small\", input=text)\n",
    "#     return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc2744-9dcd-445e-a43f-15a4fedc672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "hf_embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d46fb890-9b3e-42ee-976e-9eccb0581137",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(hf_embeddings.embed_documents(docs)).astype('float32')\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa897de3-d6e7-456f-bfaf-5c97d07644fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_groq import ChatGroq \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def retrieve(query, k):\n",
    "    query_embedding = np.array(hf_embeddings.embed_documents(query)).astype('float32')\n",
    "    \n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    _, idx = index.search(query_embedding, k)\n",
    "    \n",
    "    return [docs[i] for i in idx[0]]\n",
    "\n",
    "def generate_answer(question: str, contexts: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Generates an answer to the user's question using the provided contexts\n",
    "    and a Groq-hosted LLM via LangChain Expression Language (LCEL).\n",
    "\n",
    "    Args:\n",
    "        question (str): The user's question.\n",
    "        contexts (list[str]): A list of relevant document contexts.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated answer from the LLM.\n",
    "    \"\"\"\n",
    "    # 1. Initialize the Groq Chat model\n",
    "    llm = ChatGroq(\n",
    "        model_name='gemma2-9b-it',\n",
    "        temperature=0, # Keep temperature at 0 for more factual/less creative answers\n",
    "        groq_api_key=groq_api_key\n",
    "    )\n",
    "\n",
    "    # 2. Define the RAG prompt template\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \n",
    "         \"Answer the user question **only** with facts found in the context. \"\n",
    "         \"If the answer is not in the context, state that you cannot answer from the provided information.\\n\\n\"\n",
    "         \"Context:\\n{context}\"), # 'context' is the variable where retrieved docs will be injected\n",
    "        (\"user\", \"{question}\")\n",
    "    ])\n",
    "\n",
    "    # This creates a chain that takes 'context' and 'question' as input,\n",
    "    # formats them into the prompt, and sends to the LLM.\n",
    "    # Note: `create_stuff_documents_chain` is more for LangChain's Document objects.\n",
    "    # We are directly formatting the context string in the LCEL chain below.\n",
    "    # For a simple RAG chain:\n",
    "    generation_chain = (\n",
    "        {\n",
    "            \"context\": lambda x: \"\\n\".join(f\"- {c}\" for c in x[\"contexts\"]), # Format contexts from list of strings\n",
    "            \"question\": RunnablePassthrough() # Pass the question through\n",
    "        }\n",
    "        | prompt_template\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Invoke the chain with the question and contexts\n",
    "        result = generation_chain.invoke({\"question\": question, \"contexts\": contexts})\n",
    "        return result.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating answer with Groq/LangChain: {e}\")\n",
    "        return \"Error: Could not generate answer.\"\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# def generate_answer(question, contexts):\n",
    "#     context_text = \"\\n\".join(f\"- {c}\" for c in contexts)\n",
    "\n",
    "#     prompt_template = PromptTemplate(\n",
    "#         template=(\n",
    "#             \"Answer the user question **only** with facts found in the context.\\n\\n\"\n",
    "#             \"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "#         ),\n",
    "#         input_variables=[\"context\", \"question\"]\n",
    "#     )\n",
    "#     llm = ChatGroq(model=\"meta-llama/llama-guard-4-12b\", temperature=.5, api_key=groq_api_key)\n",
    "    \n",
    "#     chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "#     result = chain.run({\"context\": context_text, \"question\": question})\n",
    "#     return result.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c13255-3d7f-4dc1-a89b-7348ac9605d5",
   "metadata": {},
   "source": [
    "### Evaluate RAG System with Ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74a5967f-bc31-4c39-bd26-c0377ce01522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Who wrote Pride and Prejudice?\",\n",
    "    \"Where is Mount Everest located?\",\n",
    "    \"What is Mike's favorite color?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"Paris\",\n",
    "    \"Jane Austen\",\n",
    "    \"the Himalayas\",\n",
    "    \"Pink\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for question, ground_truth in zip(questions, ground_truths):\n",
    "    context = retrieve(question, k=2)\n",
    "    answer = generate_answer(question, context)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"contexts\": context,\n",
    "            \"answer\": answer,\n",
    "            \"reference\": ground_truth,\n",
    "        }\n",
    "    )\n",
    "\n",
    "evaluation_dataset = Dataset.from_list(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce20d393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the capital of France?', 'contexts': ['Mike loves the color pink more than any other color.', \"Jane Austen was an English novelist best known for 'Pride and Prejudice' and 'Sense and Sensibility'.\"], 'answer': 'I cannot answer from the provided information.', 'reference': 'Paris'}\n"
     ]
    }
   ],
   "source": [
    "print(evaluation_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "23dc0639-b149-4b1e-ad8b-313066726aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 20/20 [01:05<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'What is the capital of France?', 'contexts': ['Mike loves the color pink more than any other color.', \"Jane Austen was an English novelist best known for 'Pride and Prejudice' and 'Sense and Sensibility'.\"], 'answer': 'I cannot answer from the provided information.', 'reference': 'Paris'}, {'question': 'Who wrote Pride and Prejudice?', 'contexts': ['Mike loves the color pink more than any other color.', \"Jane Austen was an English novelist best known for 'Pride and Prejudice' and 'Sense and Sensibility'.\"], 'answer': 'Jane Austen wrote Pride and Prejudice.', 'reference': 'Jane Austen'}, {'question': 'Where is Mount Everest located?', 'contexts': ['Mike loves the color pink more than any other color.', \"Jane Austen was an English novelist best known for 'Pride and Prejudice' and 'Sense and Sensibility'.\"], 'answer': 'I cannot answer from the provided information.', 'reference': 'the Himalayas'}, {'question': \"What is Mike's favorite color?\", 'contexts': ['Mike loves the color pink more than any other color.', \"Jane Austen was an English novelist best known for 'Pride and Prejudice' and 'Sense and Sensibility'.\"], 'answer': \"Mike's favorite color is pink.\", 'reference': 'Pink'}]\n",
      "{'answer_correctness': 0.4743, 'answer_relevancy': 0.5000, 'faithfulness': 0.5000, 'context_precision': 0.3750, 'context_recall': 0.5000}\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import (\n",
    "    answer_correctness,\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "ragas_eval_llm = ChatGroq(model_name='gemma2-9b-it', temperature=0.3,max_retries=5,timeout=60, groq_api_key=groq_api_key)\n",
    "\n",
    "scores = evaluate(\n",
    "    evaluation_dataset,\n",
    "    metrics=[\n",
    "        answer_correctness,\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm=ragas_eval_llm, \n",
    "    embeddings=hf_embeddings\n",
    ")\n",
    "\n",
    "print(rows)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74891303-632c-4326-bc09-17e0e82134d1",
   "metadata": {},
   "source": [
    "### Metrics Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f60920b-3423-492d-95b4-e800a60e74a4",
   "metadata": {},
   "source": [
    "https://docs.ragas.io/en/v0.1.21/concepts/metrics/answer_correctness.html\n",
    "\n",
    "https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/faithfulness/#example\n",
    "\n",
    "https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/context_precision/\n",
    "\n",
    "https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/context_recall/\n",
    "\n",
    "https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/answer_relevance/\n",
    "\n",
    "https://docs.ragas.io/en/v0.1.21/concepts/metrics/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5737a0-3d9d-4366-9b6f-b60df84e4422",
   "metadata": {},
   "source": [
    "### High Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "48023cdd-3ed5-4da8-b48e-9754cbcb46c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_input': \"What is Mike's favorite color?\", 'retrieved_contexts': ['Mike loves the color pink more than any other color.'], 'response': \"Mike's favorite color is pink.\", 'reference': 'Pink'}]\n",
      "{'answer_correctness': 0.9023, 'answer_relevancy': 1.0000, 'faithfulness': 1.0000, 'context_precision': 1.0000, 'context_recall': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "context = docs[-1:]\n",
    "question = questions[-1]\n",
    "answer = generate_answer(question, context)\n",
    "\n",
    "rows.append(\n",
    "    {\n",
    "        \"user_input\": question,\n",
    "        \"retrieved_contexts\": context,\n",
    "        \"response\": answer,\n",
    "        \"reference\": ground_truths[-1]\n",
    "    }\n",
    ")\n",
    "\n",
    "evaluation_dataset = Dataset.from_list(rows)\n",
    "\n",
    "scores = evaluate(\n",
    "    evaluation_dataset,\n",
    "    metrics=[\n",
    "        answer_correctness,\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm=ragas_eval_llm, \n",
    "    embeddings=hf_embeddings\n",
    ")\n",
    "\n",
    "print(rows)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8a3ce-bf12-4f97-9ae7-ccde28b48ae6",
   "metadata": {},
   "source": [
    "### Wrong Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e2ec7432-3d77-4b34-a4aa-5a1855157b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:02<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_input': \"What is Mike's favorite color?\", 'retrieved_contexts': ['Vienna is the capital of Austria'], 'response': 'I cannot answer from the provided information.', 'reference': 'Pink'}]\n",
      "{'answer_correctness': 0.0304, 'answer_relevancy': 0.0000, 'faithfulness': 0.0000, 'context_precision': 0.0000, 'context_recall': 0.0000}\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "context = ['Vienna is the capital of Austria']\n",
    "question = questions[-1]\n",
    "answer = generate_answer(question, context)\n",
    "\n",
    "rows.append(\n",
    "    {\n",
    "        \"user_input\": question,\n",
    "        \"retrieved_contexts\": context,\n",
    "        \"response\": answer,\n",
    "        \"reference\": ground_truths[-1]\n",
    "    }\n",
    ")\n",
    "\n",
    "evaluation_dataset = Dataset.from_list(rows)\n",
    "\n",
    "scores = evaluate(\n",
    "    evaluation_dataset,\n",
    "    metrics=[\n",
    "        answer_correctness,\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm=ragas_eval_llm, \n",
    "    embeddings=hf_embeddings\n",
    ")\n",
    "\n",
    "print(rows)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb52a4f-9ba1-4419-b1b5-18f674cece08",
   "metadata": {},
   "source": [
    "### Correct Answer with Wrong Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c326d32a-08dc-4d55-9a18-3b8a41dc238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:01<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_input': \"What is Mike's favorite color?\", 'retrieved_contexts': ['Vienna is the capital of Austria'], 'response': \"Mike's favorite color is pink!\", 'reference': 'Pink'}]\n",
      "{'answer_correctness': 0.8988, 'answer_relevancy': 1.0000, 'faithfulness': 0.0000, 'context_precision': 0.0000, 'context_recall': 0.0000}\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "context = ['Vienna is the capital of Austria']\n",
    "question = questions[-1]\n",
    "answer = generate_answer(question, context)\n",
    "\n",
    "rows.append(\n",
    "    {\n",
    "        \"user_input\": question,\n",
    "        \"retrieved_contexts\": context,\n",
    "        \"response\": \"Mike's favorite color is pink!\",\n",
    "        \"reference\": ground_truths[-1]\n",
    "    }\n",
    ")\n",
    "\n",
    "evaluation_dataset = Dataset.from_list(rows)\n",
    "\n",
    "scores = evaluate(\n",
    "    evaluation_dataset,\n",
    "    metrics=[\n",
    "        answer_correctness,\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm=ragas_eval_llm, \n",
    "    embeddings=hf_embeddings\n",
    ")\n",
    "\n",
    "print(rows)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00463c6-aa93-4346-8cc2-b4e0688272fa",
   "metadata": {},
   "source": [
    "## Ollama Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ad58b2c-9c45-4426-82c3-b138d4df0ecf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_ollama'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LangchainLLMWrapper\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LangchainEmbeddingsWrapper\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_ollama\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOllama\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceBgeEmbeddings\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_ollama'"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894ba164-c756-4240-91e3-19b41bd1d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"qwen3:4b\", temperature=0)\n",
    "ragas_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "emb = HuggingFaceBgeEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "ragas_emb = LangchainEmbeddingsWrapper(emb)\n",
    "\n",
    "scores = evaluate(\n",
    "    evaluation_dataset,\n",
    "    metrics=[answer_correctness, answer_relevancy, faithfulness,\n",
    "             context_precision, context_recall],\n",
    "    llm=ragas_llm,\n",
    "    embeddings=ragas_emb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b952c-4fe5-4eb7-a844-b8a1ec306ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a876a35d-6c88-4352-a55d-0bcb50d71044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
